{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IES FSS CUNI\n",
    "# JEM092 Asset Pricing - Homework 1\n",
    "### Summer Semester 2023/2024\n",
    "\n",
    "### General instructions:\n",
    "* You should complete the Homework using R-language.\n",
    "* Homework should be uploaded into **\"SIS->Study group roster->Asset Pricing lecture\"** as a zip file containing:\n",
    "    + Jupyter notebook and the html version of it \n",
    "    \n",
    "    or\n",
    "    \n",
    "    + .pdf file and commented R-script\n",
    "    + For the **Task 2** and **Task 3** make sure that you comment on all the important findings. Be concise (no lengthy essays, please), although, be sure to include all important things as we cannot second-guess your work. \n",
    "     \n",
    "    \n",
    "    \n",
    "* Name of the uploaded file should be:\n",
    "    + \"HW_1_Student1surname_Student2surname.zip\"\n",
    "* **Only one member of each group should submit the solution.**\n",
    "    \n",
    "    \n",
    "* Inter-group discussion in solving the assignment is encouraged. However, each group is supposed to write their own answers in their own words. \n",
    "* Note that not only numerical results (40%) but also verbal comments (40% points) and appearance (20% points) are parts of the evaluation.\n",
    "* Not including code or sending only code will result in a **50% penalty** . \n",
    "\n",
    "Homework is subject to late penalties \n",
    "* 20% for the first day\n",
    "* 50% for the second and later day.\n",
    "\n",
    "#### Deadline: 16.4.2024 23:59\n",
    "\n",
    "## Homework 1 \n",
    "One of the biggest problems you will face while working on your master thesis (and later in your job) is data collection and preparation. Here you will get used to using *for-loops* to download quite a big amount of the data. Some of the data will be easy to get (e.g. price from finance.yahoo.com), to get the other (e.g. market capitalization), you will need to do a bit of web-scraping.\n",
    "\n",
    "In the zip file with the homework assignment, you will find a .csv file containing tickers of the S&P 500 index constituents and a zip file containing selected stocks for each student - since you should create groups of 2 students, you can pick student number of the member of the group. The stocks were randomly assigned using the following code where \"group_number\" is the student number and serves as a seed for a random number generator. \n",
    "* Please note that if you run the code on your PC, you might get slightly different random numbers due to the different hardware-software configurations of your PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m96\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m1\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (1): X1\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Warning message:\n",
      "\"package 'zip' was built under R version 4.3.3\"\n",
      "\n",
      "Attaching package: 'zip'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:utils':\n",
      "\n",
      "    unzip, zip\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 250 random stocks\n",
    "tickers<- as.character(read.csv(\"symbols_sp500_long_history.csv\")[,2]) # load S&P 500 firms\n",
    "group_number<-as.numeric(read.csv(\"students_2023_2024.csv\")[,1]) # load groups numbers \n",
    "\n",
    "firms_groups<-matrix(ncol=250,nrow=length(group_number)) # initialize empty matrix for storing firms\n",
    "for(i in 1:length(group_number)){\n",
    "    set.seed(group_number[i]) # seed for random number generation\n",
    "    firms_groups[i,]<-sample(tickers,250, replace = FALSE) # generate 250 random firms\n",
    "    }\n",
    "row.names(firms_groups)<-group_number # rename rows to names of student groups\n",
    "\n",
    "for(i in 1:length(group_number)){\n",
    "    write.csv(firms_groups[i,],paste0(group_number[i],\"_data_download.csv\")) # save data as csv\n",
    "              }\n",
    "\n",
    "# 20 random stocks from downloaded data\n",
    "rand_stock_download<-matrix(ncol=20,nrow=length(group_number))\n",
    "for(i in 1:length(group_number)){\n",
    "    set.seed(2*group_number[i])\n",
    "    rand_stock_download[i,]<-sample(firms_groups[i,],20, replace = FALSE)\n",
    "    }\n",
    "row.names(rand_stock_download)<-group_number\n",
    "\n",
    "for(i in 1:length(group_number)){\n",
    "    write.csv(rand_stock_download[i,],paste0(group_number[i],\"_rand_download.csv\")) # save data as csv\n",
    "              }\n",
    "\n",
    "# 20 random stocks from seminar data\n",
    "library(readr)\n",
    "tickers_seminar <- read_csv(\"sap100_tickers.csv\",col_names = FALSE) # load S&P 100 firms\n",
    "rand_stock_seminar<-matrix(ncol=20,nrow=length(group_number)) \n",
    "for(i in 1:length(group_number)){\n",
    "  set.seed(3*group_number[i])\n",
    "  rand_stock_seminar[i,]<-sample(tickers_seminar$X1,20, replace = FALSE)\n",
    "}\n",
    "row.names(rand_stock_seminar)<-group_number\n",
    "\n",
    "for(i in 1:length(group_number)){\n",
    "    write.csv(rand_stock_seminar[i,],paste0(group_number[i],\"_rand_seminar.csv\")) # save data as csv\n",
    "              }\n",
    "\n",
    "# zip it\n",
    "# install.packages(\"zip\")\n",
    "library(zip)\n",
    "\n",
    "Zip_Files <- list.files(pattern = \"download.csv|seminar.csv\", full.names=TRUE)  # list all generated csv files \n",
    "zip::zipr(zipfile = \"data_HW1.zip\", files = Zip_Files) # Zip the files and place the zipped file in working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li><li>TRUE</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "11. TRUE\n",
       "12. TRUE\n",
       "13. TRUE\n",
       "14. TRUE\n",
       "15. TRUE\n",
       "16. TRUE\n",
       "17. TRUE\n",
       "18. TRUE\n",
       "19. TRUE\n",
       "20. TRUE\n",
       "21. TRUE\n",
       "22. TRUE\n",
       "23. TRUE\n",
       "24. TRUE\n",
       "25. TRUE\n",
       "26. TRUE\n",
       "27. TRUE\n",
       "28. TRUE\n",
       "29. TRUE\n",
       "30. TRUE\n",
       "31. TRUE\n",
       "32. TRUE\n",
       "33. TRUE\n",
       "34. TRUE\n",
       "35. TRUE\n",
       "36. TRUE\n",
       "37. TRUE\n",
       "38. TRUE\n",
       "39. TRUE\n",
       "40. TRUE\n",
       "41. TRUE\n",
       "42. TRUE\n",
       "43. TRUE\n",
       "44. TRUE\n",
       "45. TRUE\n",
       "46. TRUE\n",
       "47. TRUE\n",
       "48. TRUE\n",
       "49. TRUE\n",
       "50. TRUE\n",
       "51. TRUE\n",
       "52. TRUE\n",
       "53. TRUE\n",
       "54. TRUE\n",
       "55. TRUE\n",
       "56. TRUE\n",
       "57. TRUE\n",
       "58. TRUE\n",
       "59. TRUE\n",
       "60. TRUE\n",
       "61. TRUE\n",
       "62. TRUE\n",
       "63. TRUE\n",
       "64. TRUE\n",
       "65. TRUE\n",
       "66. TRUE\n",
       "67. TRUE\n",
       "68. TRUE\n",
       "69. TRUE\n",
       "70. TRUE\n",
       "71. TRUE\n",
       "72. TRUE\n",
       "73. TRUE\n",
       "74. TRUE\n",
       "75. TRUE\n",
       "76. TRUE\n",
       "77. TRUE\n",
       "78. TRUE\n",
       "79. TRUE\n",
       "80. TRUE\n",
       "81. TRUE\n",
       "82. TRUE\n",
       "83. TRUE\n",
       "84. TRUE\n",
       "85. TRUE\n",
       "86. TRUE\n",
       "87. TRUE\n",
       "88. TRUE\n",
       "89. TRUE\n",
       "90. TRUE\n",
       "91. TRUE\n",
       "92. TRUE\n",
       "93. TRUE\n",
       "94. TRUE\n",
       "95. TRUE\n",
       "96. TRUE\n",
       "97. TRUE\n",
       "98. TRUE\n",
       "99. TRUE\n",
       "100. TRUE\n",
       "101. TRUE\n",
       "102. TRUE\n",
       "103. TRUE\n",
       "104. TRUE\n",
       "105. TRUE\n",
       "106. TRUE\n",
       "107. TRUE\n",
       "108. TRUE\n",
       "109. TRUE\n",
       "110. TRUE\n",
       "111. TRUE\n",
       "112. TRUE\n",
       "113. TRUE\n",
       "114. TRUE\n",
       "115. TRUE\n",
       "116. TRUE\n",
       "117. TRUE\n",
       "118. TRUE\n",
       "119. TRUE\n",
       "120. TRUE\n",
       "121. TRUE\n",
       "122. TRUE\n",
       "123. TRUE\n",
       "124. TRUE\n",
       "125. TRUE\n",
       "126. TRUE\n",
       "127. TRUE\n",
       "128. TRUE\n",
       "129. TRUE\n",
       "130. TRUE\n",
       "131. TRUE\n",
       "132. TRUE\n",
       "133. TRUE\n",
       "134. TRUE\n",
       "135. TRUE\n",
       "136. TRUE\n",
       "137. TRUE\n",
       "138. TRUE\n",
       "139. TRUE\n",
       "140. TRUE\n",
       "141. TRUE\n",
       "142. TRUE\n",
       "143. TRUE\n",
       "144. TRUE\n",
       "145. TRUE\n",
       "146. TRUE\n",
       "147. TRUE\n",
       "148. TRUE\n",
       "149. TRUE\n",
       "150. TRUE\n",
       "151. TRUE\n",
       "152. TRUE\n",
       "153. TRUE\n",
       "154. TRUE\n",
       "155. TRUE\n",
       "156. TRUE\n",
       "157. TRUE\n",
       "158. TRUE\n",
       "159. TRUE\n",
       "160. TRUE\n",
       "161. TRUE\n",
       "162. TRUE\n",
       "163. TRUE\n",
       "164. TRUE\n",
       "165. TRUE\n",
       "166. TRUE\n",
       "167. TRUE\n",
       "168. TRUE\n",
       "169. TRUE\n",
       "170. TRUE\n",
       "171. TRUE\n",
       "172. TRUE\n",
       "173. TRUE\n",
       "174. TRUE\n",
       "175. TRUE\n",
       "176. TRUE\n",
       "177. TRUE\n",
       "178. TRUE\n",
       "179. TRUE\n",
       "180. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       " [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       "[106] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       "[121] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       "[136] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       "[151] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n",
       "[166] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file.remove(Zip_Files) #remove csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Data download (8 pts)\n",
    "In the previous step, you were assigned **250** firms for which you will get the data, i.e. firms in \"**data_HW1.zip->student_number_data_download.csv**\". You will download \n",
    "* daily adjusted close price and volume data from www.finance.yahoo.com\n",
    "* Market Capitalization and Book Value per Share data from www.macrotrends.net\n",
    "* Sample period: 01.01.2010 - 28.02.2024 \n",
    "\n",
    "Getting the closing price and volume data is trivial (revise the seminar). Downloading MarketCap and Book-value per share will require writing couple more lines of code, but no worries, it is nothing complicated. The easy way is to use the  _httr_ and _rvest_ libraries - a very nice example of how to use _httr_ and _rvest_ can be found for instance here https://github.com/keithmcnulty/scraping\n",
    "\n",
    "#### Book Value per Share:\n",
    "* great source of the financial data is  www.macrotrends.net \n",
    "    + macrotrends does not like web scraping therefore you need to be a bit creative \n",
    "       - https://stackoverflow.com/questions/77142471/how-to-download-data-from-macrotrends-web-site-with-r\n",
    "    + Hint: \n",
    "        - when downloading data you should change \"user_agent\" in GET function\n",
    "        - in for-loop it is wise to add some break between individual downloads (something between 30-60 seconds should do the trick)\n",
    "* for example, Apple price ratios can be found here  https://www.macrotrends.net/stocks/charts/AAPL/apple/price-book\n",
    "    + to get the data of the other companies, you need to change the ticker (AAPL) and name of the company (apple)\n",
    "    + since you have a list of tickers, the only catch is to get the names of the companies $\\rightarrow$ try to search in google  https://www.macrotrends.net/stocks/charts/AAPL and observe what happens to the url you have searched.\n",
    "    + to automize searching for company names, use *tickers*, *for-loop*, and function *GET* to obtain url that contains the company name. Once you have the urls replace the \"AAPL/apple\" by the other \"ticker/name_of_company\"\n",
    "        - Hint: observe what happen to url if you put two tickers instead of name of company e.g. https://www.macrotrends.net/stocks/charts/AAPL/AAPL/price-book\n",
    "    + use the library _httr_ and _rvest_ and functions *read_html*, *html_table* to retrieve table. \n",
    "\n",
    "Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ url        : chr \"https://www.macrotrends.net/stocks/charts/AAPL/apple/\"\n",
      " $ status_code: int 404\n",
      " $ headers    :List of 11\n",
      "  ..$ date             : chr \"Wed, 20 Mar 2024 13:43:48 GMT\"\n",
      "  ..$ content-type     : chr \"text/html; charset=UTF-8\"\n",
      "  ..$ transfer-encoding: chr \"chunked\"\n",
      "  ..$ connection       : chr \"keep-alive\"\n",
      "  ..$ vary             : chr \"Accept-Encoding\"\n",
      "  ..$ cache-control    : chr \"max-age=14400\"\n",
      "  ..$ cf-cache-status  : chr \"HIT\"\n",
      "  ..$ age              : chr \"179\"\n",
      "  ..$ server           : chr \"cloudflare\"\n",
      "  ..$ cf-ray           : chr \"8676221fb848b348-PRG\"\n",
      "  ..$ content-encoding : chr \"gzip\"\n",
      "  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n",
      " $ all_headers:List of 2\n",
      "  ..$ :List of 3\n",
      "  .. ..$ status : int 301\n",
      "  .. ..$ version: chr \"HTTP/1.1\"\n",
      "  .. ..$ headers:List of 11\n",
      "  .. .. ..$ date             : chr \"Wed, 20 Mar 2024 13:43:48 GMT\"\n",
      "  .. .. ..$ content-type     : chr \"text/html; charset=UTF-8\"\n",
      "  .. .. ..$ transfer-encoding: chr \"chunked\"\n",
      "  .. .. ..$ connection       : chr \"keep-alive\"\n",
      "  .. .. ..$ location         : chr \"https://www.macrotrends.net/stocks/charts/AAPL/apple/\"\n",
      "  .. .. ..$ vary             : chr \"Accept-Encoding\"\n",
      "  .. .. ..$ cache-control    : chr \"max-age=14400\"\n",
      "  .. .. ..$ cf-cache-status  : chr \"HIT\"\n",
      "  .. .. ..$ age              : chr \"179\"\n",
      "  .. .. ..$ server           : chr \"cloudflare\"\n",
      "  .. .. ..$ cf-ray           : chr \"8676221f7fa6b348-PRG\"\n",
      "  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n",
      "  ..$ :List of 3\n",
      "  .. ..$ status : int 404\n",
      "  .. ..$ version: chr \"HTTP/1.1\"\n",
      "  .. ..$ headers:List of 11\n",
      "  .. .. ..$ date             : chr \"Wed, 20 Mar 2024 13:43:48 GMT\"\n",
      "  .. .. ..$ content-type     : chr \"text/html; charset=UTF-8\"\n",
      "  .. .. ..$ transfer-encoding: chr \"chunked\"\n",
      "  .. .. ..$ connection       : chr \"keep-alive\"\n",
      "  .. .. ..$ vary             : chr \"Accept-Encoding\"\n",
      "  .. .. ..$ cache-control    : chr \"max-age=14400\"\n",
      "  .. .. ..$ cf-cache-status  : chr \"HIT\"\n",
      "  .. .. ..$ age              : chr \"179\"\n",
      "  .. .. ..$ server           : chr \"cloudflare\"\n",
      "  .. .. ..$ cf-ray           : chr \"8676221fb848b348-PRG\"\n",
      "  .. .. ..$ content-encoding : chr \"gzip\"\n",
      "  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n",
      " $ cookies    :'data.frame':\t0 obs. of  7 variables:\n",
      "  ..$ domain    : logi(0) \n",
      "  ..$ flag      : logi(0) \n",
      "  ..$ path      : logi(0) \n",
      "  ..$ secure    : logi(0) \n",
      "  ..$ expiration: 'POSIXct' num(0) \n",
      "  ..$ name      : logi(0) \n",
      "  ..$ value     : logi(0) \n",
      " $ content    : raw [1:13067] 0d 0a 0d 0a ...\n",
      " $ date       : POSIXct[1:1], format: \"2024-03-20 13:43:48\"\n",
      " $ times      : Named num [1:6] 0.041269 0.000096 0.000097 0.000182 0.06019 ...\n",
      "  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n",
      " $ request    :List of 7\n",
      "  ..$ method    : chr \"GET\"\n",
      "  ..$ url       : chr \"https://www.macrotrends.net/stocks/charts/AAPL\"\n",
      "  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n",
      "  .. ..- attr(*, \"names\")= chr \"Accept\"\n",
      "  ..$ fields    : NULL\n",
      "  ..$ options   :List of 2\n",
      "  .. ..$ useragent: chr \" \"\n",
      "  .. ..$ httpget  : logi TRUE\n",
      "  ..$ auth_token: NULL\n",
      "  ..$ output    : list()\n",
      "  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n",
      "  ..- attr(*, \"class\")= chr \"request\"\n",
      " $ handle     :Class 'curl_handle' <externalptr> \n",
      " - attr(*, \"class\")= chr \"response\"\n"
     ]
    }
   ],
   "source": [
    "library(httr)\n",
    "library(rvest)\n",
    "temp<-GET(\"https://www.macrotrends.net/stocks/charts/AAPL\",user_agent(\" \"))\n",
    "str(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Market Cap:\n",
    "* getting the market capitalization is quite similar; the only difference is that the data are stored in a graph not in the table at www.macrotrends.net web\n",
    "* the values of Apple (for other companies just change ticker) market cap can be found here https://www.macrotrends.net/assets/php/market_cap.php?t=AAPL \n",
    "    + you can download the page using combinations of *GET* and *html_read* function \n",
    "    + using *html_node* and *html_children* you will get the body of the web page\n",
    "    + use *html_text* to extract data from second body node $\\rightarrow$ your data are stored between square brackets, i.e. \"[\",\"]\" $\\rightarrow$ split the text and store the dates and values of market capitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2 - Markowitz portfolio (4 pts)\n",
    "Using the data of the 20 stocks illustrate the portfolio performance by forming an efficient frontier. For the analysis, use either\n",
    "* 20 random stocks from the data you have downloaded, i.e. stocks from \"student_number_rand_download.csv\" file\n",
    "* 20 random stocks from the seminar, i.e. stocks from \"studnet_number_rand_seminar.csv\" file\n",
    "  + choose this option in case you were not able to download data in Task 1   \n",
    "\n",
    "In this task, you will form 2 portfolios\n",
    "* portfolio A will consist of stocks 1 to 10\n",
    "* portfolio B will consist of stocks 11 to 20\n",
    "\n",
    "Using the adjusted close price construct (and plot in the single figure) global minimum variance portfolio and the efficient frontier of both portfolio A and B. Since we will be working with monthly returns later in the course, use the monthly returns from the period 2015-2024 as the input for the task. **Comment the important features of the figure, e.g. which portfolio will you choose? Why? Which stock(s) is driving the shape of the frontier? etc.**\n",
    "\n",
    "> Hint:\n",
    "> * convert daily data to monthly, e.g. use \"to.period\" function\n",
    "> * from the monthly data calculate monthly returns as $$r_{i,t}=\\frac{P_{i,t}-P_{i,t-1}}{P_{i,t-1}}$$\n",
    ">   + alterantively you can calculate it as \"Close - Open\" returns, i.e. $$r_{i,t}=\\frac{P_{i,t,Close}-P_{i,t,Open}}{P_{i,t,Open}}$$\n",
    "> * obtain the Global Minimum Variance Portfolio, e.g. you can use \"optimize.portfolio\" function with proper specification\n",
    "> * form the efficient frontier for both portfolios; the constraints on the weights should be following \n",
    ">   + minimum weight should be minimum from the GMVP portfolio weights $\\rightarrow$ GMVP weights can be negative!\n",
    ">   + maximum weight should be 1\n",
    ">   + you can use \"create.EfficientFrontier\" function with proper specification\n",
    "> * your final figure should look like this\n",
    "> \n",
    "![](./sample_eff_front.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Stock index (3 pts)\n",
    "Using the monthly prices from *Task 2* create three price indexes\n",
    "* simple price weighted index, i.e. $$Index_t=\\frac{\\sum_{i=1}^N P_{i,t}}{divisor}$$\n",
    "  + as a first step when forming the price weighted index you will need to adjust the price for the stock splits! \n",
    "  + in the first period divisor will be equal to number of stocks\n",
    "* market-capitalization weighted index, $$Index_t=\\sum_{i=1}^N w_{i,t}*P_{i,t},$$\n",
    "    + where $w_{i,t}=\\frac{MKT-CAP_{i,t}}{TOTAL-MKT-CAP_t}$\n",
    "        + i.e. weighted average of prices where weights are market capitalization of individual companies \n",
    "* equally weighted index, i.e. weighted average of prices where weights are $w_i=\\frac{1}{N}$\n",
    "\n",
    "**Create the plot containing all three indexes and comment on their difference.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
